## 3.1选择排序与冒泡排序
冒泡排序需要一直交换，选择排序是比较一轮之后最终再发生交换,冒泡排序是稳定的，但选择排序不稳定；增强的冒泡排序是经过一轮冒泡后没有发生任何交换则算法可以停止了
### 习题3.1
#### 二进制位数所描述的效率：
线性算法 基本操作数为N n≈2^b 那么如果用b来描述 则算法每增加一位二进制 则需要的时间是指数级别的
也就是这个跨步是比较大的 比N一步一步的跨要大很多
#### 对于a^n mod m如何更快的进行处理？
可以使用递归的思想 拆成 ((a^n-1 mod m)*(a mod m))mod m
#### 计算二项式的值的优化
笨办法是在计算每一项时进行单独的计算 优化的办法是算出一项后在下一项乘以底数

这位用户分享了几年前写的算法书笔记，写得比较简略，现在看不太懂了。让我来分析一下这些笔记的内容。

看起来这是关于算法复杂度和一些特定算法优化的笔记。让我逐条分析：

1. **二进制位数所描述的效率**：
   - 提到线性算法基本操作数为N
   - n≈2^b，这里b应该是二进制位数
   - 如果用b来描述算法复杂度，每增加一位二进制，时间是指数级别增长
   - 这个应该是在讨论用二进制位数b来表示输入规模时，算法复杂度的变化
用户想要详细了解复杂度分析是如何计算出来的。我需要从基础概念开始，详细解释为什么这个算法的复杂度是O(2^b)，其中b是输入数字的位数。

我应该分几个层次来解释：
1. 首先明确什么是问题规模
2. 解释输入大小与位数的关系
3. 分析算法的基本操作次数
4. 将操作次数用位数表示
5. 给出具体的数值例子
6. 对比不同的复杂度度量方式

让我详细组织一下这个回答。

我来详细分析这个复杂度计算过程，从基础概念开始逐步推导。

## 1. 问题规模的定义

首先要明确**什么是问题的规模**：

**方法1：以数值N作为规模**
- 问题规模 = N
- 算法执行 N-2 次循环
- 时间复杂度 = O(N)

**方法2：以位数b作为规模**  
- 问题规模 = b（N的二进制位数）
- 这是我们要分析的情况

## 2. 位数与数值的关系

一个b位的二进制数N满足：
```
2^(b-1) ≤ N < 2^b
```

例如：
- 3位二进制：100₂ ~ 111₂，即 4 ~ 7
- 4位二进制：1000₂ ~ 1111₂，即 8 ~ 15
- b位二进制：最大值约为 2^b

**关键洞察：N ≈ 2^b**

## 3. 算法操作次数分析

```python
def is_prime(N):
    for i in range(2, N):  # 执行 N-2 次
        if N % i == 0:     # 每次一个模运算
            return False
    return True
```

- **基本操作**：模运算 `N % i`
- **操作次数**：N-2 次
- **近似**：约 N 次操作

## 4. 用位数表示操作次数

既然 N ≈ 2^b，那么：
- 操作次数 ≈ N ≈ 2^b
- **时间复杂度 = O(2^b)**

## 5. 具体数值验证

让我们用实际数字验证：

| 位数b | 数值范围 | 最大操作次数 | 2^b |
|-------|----------|--------------|-----|
| 10    | ~1,000   | ~1,000      | 1,024 |
| 20    | ~1,000,000 | ~1,000,000 | 1,048,576 |
| 30    | ~1,000,000,000 | ~1,000,000,000 | 1,073,741,824 |

可以看到操作次数确实接近 2^b。

## 6. 为什么这样度量有意义？

# 复杂度度量方式对比

## 实际应用中的考量

### 场景1：小数字素数判断
```python
# 判断 97 是否为素数
N = 97
位数 b = 7 (二进制: 1100001)
操作次数 ≈ 97 次
```
- 以数值度量：O(N) = O(97) - 很快
- 以位数度量：O(2^b) = O(2^7) = O(128) - 也很快

### 场景2：大数字素数判断（密码学应用）
```python
# 判断 1024位RSA质数
N ≈ 2^1024 (约 10^308)
位数 b = 1024
操作次数 ≈ 2^1024 次
```
- 以数值度量：O(N) = O(2^1024) - 不可行
- 以位数度量：O(2^b) = O(2^1024) - 清楚表达了不可行性

## 数学推导过程

### Step 1: 建立基本关系
- 输入：b位数字N
- 关系：2^(b-1) ≤ N < 2^b

### Step 2: 分析操作次数
- 算法循环次数：T(N) = N - 2
- 近似：T(N) ≈ N

### Step 3: 用位数表示
- 因为 N ≈ 2^b
- 所以 T(N) ≈ N ≈ 2^b
- 因此：T(b) = O(2^b)

## 复杂度类别对比

| 复杂度类型 | 位数增加1位时的增长 | 实际含义 |
|------------|-------------------|----------|
| O(b) - 线性 | 计算量 +1 | 高效算法 |
| O(b²) - 平方 | 计算量增长缓慢 | 可接受 |
| O(2^b) - 指数 | 计算量翻倍 | 不可行 |

## 优化算法对比

### 原始算法
- 时间复杂度：O(2^b)
- 实际操作：检查2到N-1的所有数

### 优化算法（检查到√N）
```python
for i in range(2, int(N**0.5) + 1):
```
- 操作次数：√N ≈ √(2^b) = 2^(b/2)
- 时间复杂度：O(2^(b/2))
- 效率提升：从指数级降到"半指数级"

### 更高级算法
- Miller-Rabin：O(k·b³) - 多项式时间
- AKS：O(b^6) - 多项式时间但常数大

## 结论

在分析大整数算法时，**以位数为度量单位**能够：
1. 更准确反映算法的实际效率
2. 便于比较不同算法的优劣  
3. 符合实际应用场景的需求
4. 与理论计算复杂性一致

我创建了一个详细的对比表来说明复杂度分析。现在我需要总结一下关键点，让用户理解为什么这个分析很重要。

## 7. 关键理解点

**核心公式推导：**
```
输入：b位数字N
关系：N ≈ 2^b  
算法：执行N次操作
结论：时间复杂度 = O(N) = O(2^b)
```

**为什么用位数度量？**
1. **实际输入特征**：我们通常说"检查一个1024位的数"而不是"检查数字2^1024"
2. **算法比较**：便于比较不同算法效率
3. **可行性判断**：清楚显示哪些算法在实际中不可用

**直观理解：**
- 位数每增加1位，数值大约翻倍
- 但算法的计算量也翻倍  
- 这就是"指数爆炸"的本质

这种分析方法在密码学、大数运算等领域特别重要，因为它准确反映了算法处理大整数时的真实效率瓶颈。
2. **对于a^n mod m的优化**：
   - 提到使用递归思想
   - 公式：((a^(n-1) mod m) * (a mod m)) mod m
   - 这看起来像是在讨论模幂运算的优化，但这个递归公式本身并不是最优的

3. **计算二项式的值的优化**：
   - 笨办法：每一项单独计算
   - 优化：算出一项后，下一项乘以底数
   - 这应该是在讨论多项式求值的霍纳法则（Horner's method）

让我详细解释一下这些概念。

我来帮你解析这些算法笔记。看起来这是关于算法复杂度和几个经典算法优化技巧的内容：

## 1. 二进制位数描述的效率问题

你的笔记想表达的是：
- 当输入规模 N ≈ 2^b（b是二进制位数）
- 如果算法是线性的 O(N)，那么用二进制位数b来描述时，复杂度变成 O(2^b)
- 这意味着每增加1位二进制，运行时间翻倍（指数增长）

**举例**：判断一个数是否为素数的简单算法，如果数字是32位整数，最坏情况需要检查约2^32次。

## 2. 快速幂取模算法 (a^n mod m)

你提到的递归方法不太完整。实际上最高效的是**快速幂算法**：

```python
def power_mod(a, n, m):
    if n == 0:
        return 1
    if n % 2 == 0:
        half = power_mod(a, n//2, m)
        return (half * half) % m
    else:
        return (a * power_mod(a, n-1, m)) % m
```

核心思想：
- 偶数次幂：a^n = (a^(n/2))^2
- 奇数次幂：a^n = a * a^(n-1)
- 时间复杂度从 O(n) 降到 O(log n)

## 3. 多项式求值优化（霍纳法则）

你说的应该是计算多项式 P(x) = a₀ + a₁x + a₂x² + ... + aₙxⁿ

**笨办法**：每项单独计算 x^i，需要 O(n²) 次乘法

**霍纳法则**：
```
P(x) = a₀ + x(a₁ + x(a₂ + x(...)))
```
从内向外计算，只需要 O(n) 次乘法

例如：2 + 3x + 4x² + 5x³ = 2 + x(3 + x(4 + x(5)))

这些都是经典的算法优化技巧，在实际编程中很常用！

用户想要更详细了解第1和第2个问题的背景。我需要：
1. 对于二进制位数描述效率的问题，需要解释为什么要用二进制位数来衡量复杂度，在什么场景下这很重要
2. 对于快速幂取模问题，需要解释这个问题的实际应用场景和为什么需要优化

让我详细展开这两个问题。

## 1. 二进制位数描述效率的问题背景

### 为什么要关注二进制位数？

在密码学和数论算法中，我们经常处理**非常大的整数**。比如：
- RSA加密使用2048位或4096位的整数
- 判断一个256位的数是否为素数

**关键问题**：当输入是一个数字N时，它的"输入规模"应该如何定义？

**两种视角的差异**：
```
数字 N = 1000000（一百万）
- 从数值角度：输入规模 = 1000000
- 从存储角度：输入规模 = log₂(1000000) ≈ 20位
```

### 实际例子：判断素数

```python
# 简单的素数判断算法
def is_prime(N):
    for i in range(2, N):
        if N % i == 0:
            return False
    return True
```

- 时间复杂度：O(N)
- 但如果N是一个b位二进制数，N ≈ 2^b
- 用位数表示：O(2^b) —— 这是**指数时间算法**！

**影响**：
- 32位整数：最多约40亿次运算（可接受）
- 256位整数：2^256次运算（宇宙热寂都算不完）

这就是为什么RSA加密的安全性依赖于大数分解的困难性——即使是"简单"的O(N)算法，对大数也是不可行的。

## 2. 快速幂取模 (a^n mod m) 的问题背景

### 应用场景

这个问题在以下领域极其重要：

**1. RSA加密/解密**
```
加密：密文 = 明文^e mod n
解密：明文 = 密文^d mod n
其中 e, d, n 都是几百到几千位的大数
```

**2. Diffie-Hellman密钥交换**
```
Alice计算：A = g^a mod p
Bob计算：B = g^b mod p
共享密钥：K = B^a mod p = A^b mod p
```

**3. 费马素性测试**
```
判断n是否为素数：检查 a^(n-1) mod n 是否等于 1
```

### 为什么需要优化？

**朴素方法的问题**：
```python
# 错误方法1：直接计算
result = (a ** n) % m  # a^n会溢出！

# 错误方法2：循环乘法
result = 1
for i in range(n):
    result = (result * a) % m  # O(n)时间
```

当n是1024位的数时，循环2^1024次是不可能的！

### 快速幂算法详解

**核心思想**：利用二进制表示
```
计算 3^13 mod 7：
13 = 1101₂ = 8 + 4 + 1
3^13 = 3^8 × 3^4 × 3^1

通过平方来快速计算：
3^1 mod 7 = 3
3^2 mod 7 = 9 mod 7 = 2
3^4 mod 7 = 2^2 mod 7 = 4
3^8 mod 7 = 4^2 mod 7 = 2

结果：3^13 mod 7 = (2 × 4 × 3) mod 7 = 24 mod 7 = 3
```

**完整实现**：
```python
def fast_power_mod(a, n, m):
    result = 1
    base = a % m
    
    while n > 0:
        # 如果n的最低位是1
        if n & 1:
            result = (result * base) % m
        # 准备下一位
        base = (base * base) % m
        n >>= 1
    
    return result
```

**复杂度对比**：
- 朴素方法：O(n) 次乘法，对1024位的n需要2^1024次
- 快速幂：O(log n) 次乘法，对1024位的n只需约1024次

这个优化使得现代密码学成为可能！没有快速幂，RSA等算法将无法实用化。

## 3.2顺序查找与蛮力字符串匹配
### 习题3.2
### 两个仪器 测试使其坏的最高楼层 一个坏了以后可以用另一个 最佳方法是：
√n查找法 以√n为步长进行测试 具体到某步中 再以1为单位进行测试 效率不会低于2√n 无法使用二分 因为只有两个仪器 二分只能查找两次
这个笔记似乎是在描述一个经典的算法问题，叫做"两个鸡蛋问题"（Two Egg Problem），也可能是"掉落测试问题"。让我来分析一下这个笔记的内容：

1. "两个仪器 测试使其坏的最高楼层" - 这应该是说有两个相同的仪器（比如鸡蛋），要找出使其破坏的最高楼层。这是一个经典问题：在一栋n层的大楼中，找出鸡蛋摔不坏的最高楼层。

2. "一个坏了以后可以用另一个" - 这说明有两个仪器，如果第一个坏了，还可以用第二个。

3. "√n查找法 以√n为步长进行测试" - 这是说先用√n作为步长来测试。

4. "具体到某步中 再以1为单位进行测试" - 当找到大概范围后，再用1为单位精确测试。

5. "效率不会低于2√n" - 这应该是说最坏情况下的测试次数。

6. "无法使用二分 因为只有两个仪器 二分只能查找两次" - 这解释了为什么不能用二分法。

让我详细解释这个经典问题和算法：

经典的"两个鸡蛋问题"：
- 有一栋N层的大楼和两个相同的鸡蛋
- 存在一个临界楼层F，在F层及以下扔鸡蛋不会破，在F+1层及以上会破


- 我需要找出最优策略，用最少的测试次数确定这个临界楼层
- 关键是在有限的测试机会中，通过聪明的步长选择，最小化总体测试次数

采用根号n的测试方法：
1. 第一个鸡蛋以等间距√n跳跃测试
2. 第二个鸡蛋进行精确的逐层检测

最坏情况下测试效率：
- 第一个鸡蛋探测范围约√n次
- 第二个鸡蛋精确定位同样约√n次
- 总体测试次数控制在2√n左右

实际上，还存在更复杂的动态规划和非等距测试方案，可以进一步优化测试策略。

这个笔记描述的是经典的"**两个鸡蛋问题**"（Two Egg Problem），这是一个著名的算法优化问题。让我来解释一下：

## 问题背景
- 有一栋 N 层的大楼和两个相同的"仪器"（通常用鸡蛋作比喻）
- 存在一个临界楼层 F，在这个楼层及以下扔不会坏，超过这个楼层就会坏
- 目标：用最少的测试次数找出这个临界楼层
- 限制：仪器坏了就不能再用

## 为什么不能用二分法
你的笔记提到"无法使用二分 因为只有两个仪器"是对的：
- 二分法需要在测试失败后还能继续测试很多次
- 但如果第一个仪器在高楼层坏了，第二个就只能从低楼层开始逐层测试，效率很低

## √n 查找法的策略

**第一阶段**：用第一个仪器以 √n 为步长测试
- 在 √n, 2√n, 3√n, ... 楼层测试，直到第一个仪器坏掉

**第二阶段**：用第二个仪器精确定位
- 从上次没坏的楼层开始，以1为单位逐层测试

## 时间复杂度分析
- 第一个仪器最多测试 √n 次
- 第二个仪器最多测试 √n 次（因为两个测试点间隔最多 √n 层）
- **总测试次数：最多 2√n 次**

## 举例说明
假设100层楼（√100 = 10）：
1. 第一个仪器在 10、20、30、40、50、60 层测试，假设在60层坏了
2. 第二个仪器从51层开始逐层测试：51、52、53...直到找到临界点

这确实是一个巧妙的算法，在两个仪器限制下达到了较优的时间复杂度！

### 为什么从右向左字符串匹配更好
Comparing pairs of the pattern and text characters righ-to-left can allow
farther pattern shifts after a mismatch
### 蛮力算法查找以a开头 以b结尾的子串线性改进版
存储a的个数A 和 要求的子串数目sub,初始值均为0,从左到右碰到一个a则为增加a的数目，碰到一个b，则sub加当前A，最后返回sub

## 3.3最近对和凸包问题的蛮力算法
### 最近对问题
典型的蛮力法解决的问题，蛮力法也有技巧进行优化，比如不要重复计数等等
更进一步的优化是 按照X Y的顺序分别排序 计算相邻点的距离 注意是两次排序 
### 凸包问题
N^3的算法 检测两点连线 是否把其他所有点隔在一侧 如果是 则该两点算凸包内 凸包上的点是极点
### 线性时间内找出一对极点
X最小的点(如果有x相同的则取Y最小的) 和最大的点
### 奇数派问题
每个人手里有一块蛋糕 会扔给他最近的人 证明如果是奇数个人 则一定会有人没有被扔到
#### 解决的思路是最近对和数学归纳法，考虑3个人的情况，最近对会互相仍蛋糕，那么第3个人不会被扔到
考虑n个人的情况 最近对互相扔 如果没有其他人扔蛋糕给最近对 则回归到n-2的情况，按照归纳法的假设，这n-2中会有人没有被扔到；如果有人扔给最近对 剩下的n-2个人的蛋糕显然已经不能满足扔给他们中每个人蛋糕 因为有一块已经扔出去了
## 3.4 穷举查找
## 旅行商问题
最短哈密顿回路问题 哈密顿回路：由一点开始 不重复的遍历到所有点再回到起点的回路 一般蛮力方法是先生成排列 再进行检查是否中间有断连的情况
### 欧拉回路
欧拉回路是由一点开始 不重复的遍历到所有路径再回到起点的回路 判断一个图是否具有欧拉回路就是判断每个点的度是否为偶数 对于n×n的邻接矩阵 显然时间线效率为O(n^2)
### 全排列的生成
在手动生成排列时有一个重复的动作，就是选择下一个子节点，这个就是实现递归的基础，对于点I,我们可以用I到n之间的点，与I互换，即I的位置是代表实际的下一个节点，递归调用结束后，再换回来，供下一个排列使用；复制法,初始是只有一个set,vector的pair组成的vector,每次从set里拿出去一个，这个放到记录的vector里，剩下的set复制给内层循环，比较费事的是每次都必须复制，vector和set都要，比较消耗空间；   
另外也可以使用Stack,每次拿到栈顶的序列，记录序列中剩下的元素，同时需要记录路径;另外递归也有一种思路是dfs递归访问，记录visit值，从非visit开始进行下一层的访问，内层调用访问完毕后将visit置0；栈版本也可以借鉴该思路，到叶节点时对该元素的visit进行置0,则不需要进行visit的复制，只需用指针   
非递归字典序的实现：
首先需要输出字典序最小的序列，即从左到右都是按照字典序从小到大排列，然后从右至左依次扫描到某个元素j小于其下一个元素j+1，在j+1和n之间从n到j+1扫描到第一个大于j的元素k（这时候j+1到n之间已经是最大序列了），即j+1到n之间大于j的最小元素,将k与j互换，再将现在的j+1到n之间由大到小的顺序变为由小到大
全排列算法总结：
https://blog.csdn.net/yoer77/article/details/53458612
### 有重复元素的全排列生成
有重复元素时，会生成多余的结果；因而在递归交换时，要检查交换两者之间又没有等于后者的，有的话不做递归访问；
对于dfs递归版本，要剪掉在同一层之间相同的节点，即用一个临时变量记录同一层的节点，有相同的则不再进行递归访问；  
对于字典序就没有这个问题

## 背包问题
首先穷举出所有的组合（物品数目种类是有限的)，再check是否背包背得下，然后再得出一个价值，进行比较
## 分配问题
## dfs
完整的dfs/bfs给每个节点记录距离/访问次数,借此标记已访问，以防止出现回边/交叉边访问，由于router这种代码没有环状路线，并且有向，所以并没有考虑这种情况；另外，标准的dfs/bfs要求访问每一个点，所以每一个点都要作为起点
## bfs
除了和dfs一样检查无环性和连通性，还可以用来求最短路径,可以适用于任意无向图的单点最短路径问题
### bfs记录路径的方法
可以通过倒着从特定终点进行一次bfs的方式，加上条件cur_dis=prev_dis+1,就可以找到要的那条特定终点特定长度的路径，具体可见
[bfs路径记录](https://www.cnblogs.com/astonc/p/10639091.html)
算法书中建议的回溯法，需要队列能加label(pre)，并且进行递归回溯：[回溯法](https://www.jianshu.com/p/7570ce8aa833)
比较耗费空间，但不需要再来一次的方法参考：[正向记录](https://blog.csdn.net/lanshan1111/article/details/90243923)
[两种bfs路径记录的思路](https://www.cnblogs.com/Lis-/p/10572619.html)，是以上方法的体现,但记录前序使用了循环数组
除了进行两边bfs的方法，其他方法均要在经过的每个点都记录pre或者整个正向路径，比较耗费空间
dfs应该也是用相同的思路来记录路径
### 标准形式
对于dfs/bfs,入队/栈和出队/栈的时机都可以做访问或者check，没有明显的区别，根据需要来做
### 习题3.5
#### 证明对于无向图bfs树的交叉边，要么是连接同层的顶点，要么是链接bfs树相邻层的顶点
反证法：如果交叉边连接两层及其以上的顶点u和v，则对于距离d(u)和d(v)，d(u)>=d(v)+2,而如果有交叉边，d(u)=d(v)+1,显然矛盾
#### 三壶问题
最先要做的是生成下一个状态的函数，注意其中的指针问题；这个状态指的是3个水壶之间一个是倒入的水壶，一个是接收的水壶，c 3 2种可能产生的状态进行bfs遍历
```cpp
vector<int*> new_state(int state[3]){//vector<int[3]>是不允许的
    vector<int*> res;
    for (int i = 0; i <3 ; ++i) {
        if(state[i]>0) {
            for (int j = 0; j < 3; ++j) {
                if (j != i) {
                    int* tmp=new int[3];//如果在这里使用int tmp[3],这种在栈区的使用方法，函数结束后指向的内存会被释放，因而会res里的结果会是乱码
                    tmp[0]=state[0];//tmp[3]放在外面更不对，因此使用new,堆区内存不会自动释放
                    tmp[1]=state[1];
                    tmp[2]=state[2];
                    if(full[j]-state[j]>state[i]) {
                       tmp[j]+=state[i];
                       tmp[i]=0;
                   } else{
                       tmp[j]=full[j];
                       tmp[i]-=full[j]-state[j];
                   }
                    res.push_back(tmp);
                }
            }
        }
    }
    return res;
}
```
与本文无关的加一条：https://www.cnblogs.com/bookdrip/articles/9844675.html
数组指针指向的内存和该指针本身地址是一个位置，猜想这是因为其地址是一个二维数组首地址，数组不管几个维度，首地址都在一起。
方便起见，最后还是使用了array,完整代码如下：
```cpp
#include "common.h"
array<int,3> state;
int full[3];
struct node{
    array<int,3> state;
    vector<array<int,3>> road;
};
vector<array<int,3>> visited;
vector<array<int,3>> new_state(array<int,3> state){
    vector<array<int,3>> res;
    for (int i = 0; i <3 ; ++i) {
        if(state[i]>0) {
            for (int j = 0; j < 3; ++j) {
                if (j != i) {
                    array<int,3> tmp=state;
                    if(full[j]-state[j]>state[i]) {
                       tmp[j]+=state[i];
                       tmp[i]=0;
                   } else{
                       tmp[j]=full[j];
                       tmp[i]-=full[j]-state[j];
                   }
                    if(find(visited.begin(),visited.end(),tmp)==visited.end())
                    {
                        res.push_back(tmp);
                        visited.push_back(tmp);
                    }
                }
            }
        }
    }
    return res;
}
vector<array<int,3>> bfs(array<int,3> state){
    queue<node> qs;
    node tmp_node,ttmp_node;
    tmp_node.state=state;
    qs.push(tmp_node);
    vector<array<int,3>>nState;
    while (!qs.empty()){
        tmp_node=qs.front();
        qs.pop();
        nState=new_state(tmp_node.state);
        for (auto tmp_state:nState ) {
            ttmp_node.state=tmp_state;
            ttmp_node.road=tmp_node.road;
            ttmp_node.road.push_back(tmp_state);
            for (int i = 0; i <3 ; ++i) {
                if(tmp_state[i]==4) return ttmp_node.road;
            }
            qs.push(ttmp_node);
        }
    }
    ttmp_node.road.clear();
    return ttmp_node.road;

}
int main(){
    //state[1]=3;
    state[2]=8;
    full[0]=3;
    full[1]=5;
    full[2]=8;
    vector<array<int,3>>res=bfs(state);
    return 0;
}
```
